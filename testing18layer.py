# -*- coding: utf-8 -*-
"""Testing18Layer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fFtHN34Txk6gQ4PCvqHYY14f5uOHVoBB

#Import library dan drive
"""

import os
from tqdm import tqdm
import numpy as np
import matplotlib.pyplot as plt
import random
import pandas as pd
import torch
import torchvision
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import models

from sklearn.cluster import KMeans
from sklearn.cluster import AgglomerativeClustering
from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score, adjusted_rand_score
from sklearn.metrics import accuracy_score
from sklearn.manifold import TSNE
from sklearn.metrics import pairwise_distances
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
from PIL import Image

from sklearn.model_selection import train_test_split

from itertools import combinations

from tabulate import tabulate

from google.colab import drive
drive.mount('/content/drive')

"""#Kelas Autoencoder"""

class EncoderVGG(nn.Module):
    '''Encoder of image based on the architecture of VGG-16 with batch normalization.
    Args:
        pretrained_params (bool, optional): If the network should be populated with pre-trained VGG parameters.
            Defaults to True.
    '''
    channels_in = 3
    channels_code = 512

    def __init__(self, pretrained_params=True):
        super(EncoderVGG, self).__init__()
        vgg = models.vgg16_bn(pretrained=pretrained_params)
        del vgg.classifier
        del vgg.avgpool

        self.encoder = self._encodify_(vgg)

    def forward(self, x):
        '''Execute the encoder on the image input
        Args:
            x (Tensor): image tensor
        Returns:
            x_code (Tensor): code tensor
            pool_indices (list): Pool indices tensors in order of the pooling modules
        '''
        pool_indices = []
        x_current = x
        for module_encode in self.encoder:
            output = module_encode(x_current)

            # If the module is pooling, there are two outputs, the second the pool indices
            if isinstance(output, tuple) and len(output) == 2:
                x_current = output[0]
                pool_indices.append(output[1])
            else:
                x_current = output

        return x_current, pool_indices

    @staticmethod
    def dim_code(img_dim):
        '''Convenience function to provide dimension of code given a square image of specified size. The transformation
        is defined by the details of the VGG method. The aim should be to resize the image to produce an integer
        code dimension.
        Args:
            img_dim (int): Height/width dimension of the tentative square image to input to the auto-encoder
        Returns:
            code_dim (float): Height/width dimension of the code
            int_value (bool): If False, the tentative image dimension will not produce an integer dimension for the
                code. If True it will. For actual applications, this value should be True.
        '''
        value = img_dim / 2**5
        int_value = img_dim % 2**5 == 0
        return value, int_value

    def _encodify_(self, encoder):
        '''Create list of modules for encoder based on the architecture in VGG template model.

        In the encoder-decoder architecture, the unpooling operations in the decoder require pooling
        indices from the corresponding pooling operation in the encoder. In VGG template, these indices
        are not returned. Hence the need for this method to extent the pooling operations.
        Args:
            encoder : the template VGG model
        Returns:
            modules : the list of modules that define the encoder corresponding to the VGG model
        '''
        modules = nn.ModuleList()
        for module in encoder.features:
            if isinstance(module, nn.MaxPool2d):
                module_add = nn.MaxPool2d(kernel_size=module.kernel_size,
                                          stride=module.stride,
                                          padding=module.padding,
                                          return_indices=True)
                modules.append(module_add)
            else:
                modules.append(module)

        return modules

class DecoderVGG(nn.Module):
    '''Decoder of code based on the architecture of VGG-16 with batch normalization.

    The decoder is created from a pseudo-inversion of the encoder based on VGG-16 with batch normalization. The
    pesudo-inversion is obtained by (1) replacing max pooling layers in the encoder with max un-pooling layers with
    pooling indices from the mirror image max pooling layer, and by (2) replacing 2D convolutions with transposed
    2D convolutions. The ReLU and batch normalization layers are the same as in the encoder, that is subsequent to
    the convolution layer.
    Args:
        encoder: The encoder instance of `EncoderVGG` that is to be inverted into a decoder
    '''
    channels_in = EncoderVGG.channels_code
    channels_out = 3

    def __init__(self, encoder):
        super(DecoderVGG, self).__init__()

        self.decoder = self._invert_(encoder)

    def forward(self, x, pool_indices):
        '''Execute the decoder on the code tensor input
        Args:
            x (Tensor): code tensor obtained from encoder
            pool_indices (list): Pool indices Pytorch tensors in order the pooling modules in the encoder
        Returns:
            x (Tensor): decoded image tensor
        '''
        x_current = x

        k_pool = 0
        reversed_pool_indices = list(reversed(pool_indices))
        for module_decode in self.decoder:

            # If the module is unpooling, collect the appropriate pooling indices
            if isinstance(module_decode, nn.MaxUnpool2d):
                x_current = module_decode(x_current, indices=reversed_pool_indices[k_pool])
                k_pool += 1
            else:
                x_current = module_decode(x_current)

        return x_current

    def _invert_(self, encoder):
        '''Invert the encoder in order to create the decoder as a (more or less) mirror image of the encoder

        The decoder is comprised of two principal types: the 2D transpose convolution and the 2D unpooling. The 2D transpose
        convolution is followed by batch normalization and activation. Therefore as the module list of the encoder
        is iterated over in reverse, a convolution in encoder is turned into transposed convolution plus normalization
        and activation, and a maxpooling in encoder is turned into unpooling.
        Args:
            encoder (ModuleList): the encoder
        Returns:
            decoder (ModuleList): the decoder obtained by "inversion" of encoder
        '''
        modules_transpose = []
        for module in reversed(encoder):

            if isinstance(module, nn.Conv2d):
                kwargs = {'in_channels' : module.out_channels, 'out_channels' : module.in_channels,
                          'kernel_size' : module.kernel_size, 'stride' : module.stride,
                          'padding' : module.padding}
                module_transpose = nn.ConvTranspose2d(**kwargs)
                module_norm = nn.BatchNorm2d(module.in_channels)
                module_act = nn.ReLU(inplace=True)
                modules_transpose += [module_transpose, module_norm, module_act]

            elif isinstance(module, nn.MaxPool2d):
                kwargs = {'kernel_size' : module.kernel_size, 'stride' : module.stride,
                          'padding' : module.padding}
                module_transpose = nn.MaxUnpool2d(**kwargs)
                modules_transpose += [module_transpose]

        # Discard the final normalization and activation, so final module is convolution with bias
        modules_transpose = modules_transpose[:-2]

        return nn.ModuleList(modules_transpose)

class AutoEncoderVGG(nn.Module):
    '''Auto-Encoder based on the VGG-16 with batch normalization template model. The class is comprised of
    an encoder and a decoder.
    Args:
        pretrained_params (bool, optional): If the network should be populated with pre-trained VGG parameters.
            Defaults to True.
    '''
    channels_in = EncoderVGG.channels_in
    channels_code = EncoderVGG.channels_code
    channels_out = DecoderVGG.channels_out

    def __init__(self, pretrained_params=True):
        super(AutoEncoderVGG, self).__init__()

        self.encoder = EncoderVGG(pretrained_params=pretrained_params)
        self.decoder = DecoderVGG(self.encoder.encoder)

    @staticmethod
    def dim_code(img_dim):
        '''Convenience function to provide dimension of code given a square image of specified size. The transformation
        is defined by the details of the VGG method. The aim should be to resize the image to produce an integer
        code dimension.
        Args:
            img_dim (int): Height/width dimension of the tentative square image to input to the auto-encoder
        Returns:
            code_dim (float): Height/width dimension of the code
            int_value (bool): If False, the tentative image dimension will not produce an integer dimension for the
                code. If True it will. For actual applications, this value should be True.
        '''
        return EncoderVGG.dim_code(img_dim)

    @staticmethod
    def state_dict_mutate(encoder_or_decoder, ae_state_dict):
        '''Mutate an auto-encoder state dictionary into a pure encoder or decoder state dictionary
        The method depends on the naming of the encoder and decoder attribute names as defined in the auto-encoder
        initialization. Currently these names are "encoder" and "decoder".
        The state dictionary that is returned can be loaded into a pure EncoderVGG or DecoderVGG instance.
        Args:
            encoder_or_decoder (str): Specification if mutation should be to an encoder state dictionary or decoder
                state dictionary, where the former is denoted with "encoder" and the latter "decoder"
            ae_state_dict (OrderedDict): The auto-encoder state dictionary to mutate
        Returns:
            state_dict (OrderedDict): The mutated state dictionary that can be loaded into either an EncoderVGG
                or DecoderVGG instance
        Raises:
            RuntimeError : if state dictionary contains keys that cannot be attributed to either encoder or decoder
            ValueError : if specified mutation is neither "encoder" or "decoder"
        '''
        if not (encoder_or_decoder == 'encoder' or encoder_or_decoder == 'decoder'):
            raise ValueError('State dictionary mutation only for "encoder" or "decoder", not {}'.format(encoder_or_decoder))

        keys = list(ae_state_dict)
        for key in keys:
            if 'encoder' in key or 'decoder' in key:
                if encoder_or_decoder in key:
                    key_new = key[len(encoder_or_decoder) + 1:]
                    ae_state_dict[key_new] = ae_state_dict[key]
                    del ae_state_dict[key]

                else:
                    del ae_state_dict[key]

            else:
                raise RuntimeError('State dictionary key {} is neither part of encoder or decoder'.format(key))

        return ae_state_dict

    def forward(self, x):
        '''Forward the autoencoder for image input
        Args:
            x (Tensor): image tensor
        Returns:
            x_prime (Tensor): image tensor following encoding and decoding
        '''
        code, pool_indices = self.encoder(x)
        x_prime = self.decoder(code, pool_indices)

        return x_prime

    def predict(self, image):
        # Lakukan encoding menggunakan encoder
        features, _ = self.encoder(image)

        # Melakukan prediksi cluster menggunakan model clustering yang sudah dilatih sebelumnya
        cluster_labels = model_path.predict(features)

        return cluster_labels

model = AutoEncoderVGG()

"""#preprocessing"""

# Load the pneumonia x-ray dataset into PyTorch
transform = torchvision.transforms.Compose([
    torchvision.transforms.Resize((256, 256)),
    torchvision.transforms.ToTensor()
])

path = '/content/drive/MyDrive/BerkasKuliah/Skripsi/dataset_testing'
dataset = torchvision.datasets.ImageFolder(path, transform=transform)
dataloader = DataLoader(dataset, batch_size=32, shuffle=True)

dataset

model_path = '/content/drive/MyDrive/BerkasKuliah/Skripsi/model/vgg_autoencoder_model_70_latih.pth'

if torch.backends.mps.is_available():
    device = torch.device("mps")
    x = torch.ones(1, device=device)
    print(x)
elif torch.cuda.is_available():
    device = torch.device("cuda")
    x = torch.ones(1, device=device)
    print(x)
else:
    print("mps/cuda device not found.")

model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))
modeltesting = model.to(device)
modeltesting.eval()

# Check the device for the model parameters
next(modeltesting.parameters()).device

"""#Evaluasi

"""

encoded_features = []
true_labels = []
model.eval()
with torch.no_grad():
    for images, labels in tqdm(dataloader, desc='Processing images'):
        images = images.to(device)
        features = model.encoder(images)
        encoded_features.append(features[0].cpu())
        true_labels.extend(labels)

encoded_features = torch.cat(encoded_features)
encoded_features = encoded_features.view(encoded_features.size(0), -1)

# Set the desired number of clusters and labels
num_clusters = 15
num_labels = 4

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # Perform kmeans clustering on encoded features
# kmeans = KMeans(n_clusters=num_clusters, random_state=42)
# predicted_labels_KMeans = kmeans.fit_predict(encoded_features)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # Agglomerative Clustering
# #take 30 minutes
# AC = AgglomerativeClustering(n_clusters=num_clusters)
# labels = AC.fit_predict(encoded_features)

# Select the label of interest
label_of_interest = 3

# Find the indices of images with the selected label
label_indices = [idx for idx, label in enumerate(dataset.targets) if label == label_of_interest]

# Select 5 random image indices from the images with the selected label
random_indices = random.sample(label_indices, 5)

# Display the random images with the selected label
fig, axes = plt.subplots(1, 5, figsize=(12, 2))

for i, idx in enumerate(random_indices):
    image, true_label = dataset[idx]
    axes[i].imshow(image.permute(1, 2, 0))
    axes[i].axis('off')
    axes[i].set_title(f"Cluster: {predicted_labels_KMeans[idx]}, True Label: {true_label}")

plt.tight_layout()
plt.show()

# Save the figure
fig.savefig('/content/drive/MyDrive/BerkasKuliah/Skripsi/hasil_testing/HasilGambar/gambarepoch70_testing_15cluster(1).png')

import random

# Number of labels (assuming labels from 0 to 3)
num_labels = 4

# Create a figure and subplots for the grid
fig, axes = plt.subplots(num_labels, 4, figsize=(10, 12))

# Iterate over each label
for label in range(num_labels):
    # Find the indices of images belonging to the current label
    label_indices = [idx for idx, lbl in enumerate(predicted_labels_KMeans) if lbl == label]

    # Check if there are enough indices for sampling
    if len(label_indices) >= 4:
        # Select 4 random image indices from the current label
        random_indices = random.sample(label_indices, 4)

        # Display the images from the current label in a row
        for i, idx in enumerate(random_indices):
            image, true_label = dataset[idx]
            axes[label, i].imshow(image.permute(1, 2, 0))
            axes[label, i].axis('off')
            axes[label, i].set_title(f"Cluster: {label}, True Label: {true_label}")
    else:
        # Display a message if there are not enough samples for the current label
        axes[label, 0].text(0.5, 0.5, "Not enough samples", ha='center', va='center')
        axes[label, 0].axis('off')

plt.tight_layout()
plt.show()

# Save the figure
fig.savefig('/content/drive/MyDrive/BerkasKuliah/Skripsi/hasil_testing/HasilGambar/gambarepoch70_testing_15cluster.png')

"""#Cek Jumlah Cluster dan Label"""

# Initializing the matrix to store label counts in each cluster
cluster_label_counts = [[0] * num_labels for _ in range(num_clusters)]

# Counting label occurrences in each cluster
for cluster_idx, label_idx in zip(predicted_labels_KMeans, true_labels):
    if cluster_idx < num_clusters:  # Check if cluster index is within range
        cluster_label_counts[cluster_idx][label_idx] += 1

# Printing the clustering results
for cluster_idx, label_counts in enumerate(cluster_label_counts):
    if cluster_idx < num_clusters:  # Check if cluster index is within range
        print(f"Cluster {cluster_idx + 1}:")
        for label_idx, count in enumerate(label_counts):
            print(f"Label {label_idx}: {count}")

df = pd.DataFrame(cluster_label_counts)
# Menambahkan label kolom pada DataFrame
df.columns = [f"Label {label_idx}" for label_idx in range(num_labels)]
# Menambahkan label baris pada DataFrame
df.index = [f"Cluster {cluster_idx + 1}" for cluster_idx in range(num_clusters)]
# Membuat folder jika belum ada
folder_path = '/content/drive/MyDrive/BerkasKuliah/Skripsi/hasil_testing'
os.makedirs(folder_path, exist_ok=True)

# Menyimpan DataFrame ke dalam file Excel
file_path = os.path.join(folder_path, 'hasil_clustering_testing_epoch_70_15cluster.xlsx')
df.to_excel(file_path, index=True)

# Labeling each cluster
cluster_labels = []
for cluster_idx, label_counts in enumerate(cluster_label_counts):
    # Determining the label with the highest count in the cluster
    max_label_count = max(label_counts)
    max_label_indices = [i for i, count in enumerate(label_counts) if count == max_label_count]
    cluster_label = max_label_indices[0]  # Taking the first label with the highest count
    cluster_labels.append(cluster_label)

# Creating a label mapping for clusters to desired labels
label_mapping = {
    0: 'Pneumonia',
    1: 'Pneumothorax',
    2: 'Tuberculosis',
    3: 'Normal'
}

# Mapping cluster labels to desired labels
cluster_labels_mapped = [label_mapping[label] for label in cluster_labels]

# Displaying the labeling results
for cluster_idx, label in enumerate(cluster_labels_mapped):
    print(f"Cluster {cluster_idx + 1} label: {label}")

# Menyimpan hasil pelabelan ke dalam file CSV
df = pd.DataFrame({'Cluster': range(1, num_clusters+1), 'Label': cluster_labels_mapped})
6
df.to_csv('/content/drive/MyDrive/BerkasKuliah/Skripsi/hasil_testing/cluster_labels_epoch70_testing_15cluster.csv', index=False)

"""###ngecek kesamaan"""

'''
# Membaca file cluster_labels dengan encoding yang sesuai
file_path = '/content/drive/MyDrive/BerkasKuliah/Skripsi/hasiltrain/HasilDatapercluster/HasilLabel/cluster_labels_epoch10(4cluster).xlsx'
df_train = pd.read_excel(file_path)

# Membaca file cluster_labels_epoch30_testing.csv
file_path_testing = '/content/drive/MyDrive/BerkasKuliah/Skripsi/hasil_testing/cluster_labels_epoch50_testing_15cluster.csv'
df_testing = pd.read_csv(file_path_testing)

# Membandingkan hasil pelabelan
comparison = df_train['Label'] == df_testing['Label']

# Menampilkan hasil perbandingan
print(f"Hasil Perbandingan:\n{comparison}")

# Menampilkan kesimpulan
if comparison.all():
    print("Hasil pelabelan pada data testing sama dengan hasil pelabelan pada data training.")
else:
    print("Hasil pelabelan pada data testing berbeda dengan hasil pelabelan pada data training.(epoch 50 cluster15)")
'''

"""#Lihat Purity, Completeness, Precision, Recall,F1-score keseluruhan data

#Lihat Akurasi

##Rand Index
"""

#panggil datalabel
cluster_label_counts = pd.read_excel('/content/drive/MyDrive/BerkasKuliah/Skripsi/hasil_testing/Hasilcluster18layer/hasil_clustering_testing_epoch_10_4cluster.xlsx')
cluster_label_counts.drop(cluster_label_counts.filter(regex="Unname"),axis=1, inplace=True)
cluster_label_counts = cluster_label_counts.values.tolist()
cluster_label_counts

#menggabungkan cluster dengan label yang sama menjadi satu
cluster_label_counts.append(pneu.tolist())
cluster_label_counts.append(pnemu.tolist())
cluster_label_counts.append(tuber.tolist())
cluster_label_counts.append(normal.tolist())
cluster_label_counts = np.array(cluster_label_counts)

def compute_TP_FP_FN_TN(conf_matrix):
    # Assuming conf_matrix is a NumPy array
    TP = np.diag(conf_matrix)
    FP = np.sum(conf_matrix, axis=1) - TP
    FN = np.sum(conf_matrix, axis=0) - TP
    TN = np.sum(conf_matrix) - (TP + FP + FN)

    return TP, FP, FN, TN

TP, FP, FN, TN = compute_TP_FP_FN_TN(cluster_label_counts)

print(f'True Positives (TP): {TP}')
print(f'False Positives (FP): {FP}')
print(f'True Negatives (TN): {TN}')
print(f'False Negatives (FN): {FN}')

results = []

# Calculate TP, FN, FP, and TN for each cluster
TP_list = []
FN_list = []
FP_list = []
TN_list = []

entropy = []

total_samples = 756  # Total number of samples in the dataset
cluster_idx = 0
for label_counts in cluster_label_counts:
    entropy = []
    cluster_idx
    print(f"Label {cluster_idx + 1}:")

    max_label_count = max(label_counts)  # Maximum label count in the cluster

    rand_index = (TP + TN) / (TP + TN + FP + FN)

    # Handling division by zero in precision
    precision = TP / (TP + FP)

    recall = TP / (TP + FN)

    # Handling division by zero in F1 score

    f1_score = 2 * (precision * recall) / (precision + recall)

    # Calculating entropy
    if sum(label_counts) == 0:
      entropy = 0
    else:
      total = sum(label_counts)
      for predict in label_counts:
        div = predict/total
        if div == 0:
          equation = 0.0
        elif div != 0:
          equation = (-div)*math.log2(div)
        entropy.append(equation)

      entropy = (sum(entropy))

    # Calculating purity
    purity = max_label_count / sum(label_counts)# purity juga di cek

    # Creating data for Confusion Matrix
    confusion_table = [
        ["Con_Mat", "Jumlah"],
        ["True Positive (TP)", TP],
        ["False Negative (FN)", FN],
        ["False Positive (FP)", FP],
        ["True Negative (TN)", TN]
    ]

    # Creating data for rand_index
    rand_index_table = [
        ["Metric", "Value"],
        ["rand_index", rand_index],
        ["Precision", precision],
        ["Recall", recall],
        ["F1 Score", f1_score],
        ["Entropy", entropy],
        ["Purity", purity]
    ]

    # Displaying Confusion Matrix
    print("**Confusion Matrix Results**")
    print(tabulate(confusion_table, headers="firstrow", tablefmt="grid"))
    print()

    # Displaying rand_index Results
    print("**rand_index Results**")
    print(tabulate(rand_index_table, headers="firstrow", tablefmt="grid"))
    print()


    # Menambahkan hasil per cluster ke dalam list
    results.append({
        'Cluster': cluster_idx + 1,
        'True Positive (TP)': TP,
        'False Negative (FN)': FN,
        'False Positive (FP)': FP,
        'True Negative (TN)': TN,
        'rand_index': rand_index,
        'Precision': precision,
        'Recall': recall,
        'F1 Score': f1_score,
        'Entropy': entropy,
        'Purity': purity
    })
    cluster_idx += 1

# Membuat DataFrame dari hasil per cluster
df_results = pd.DataFrame(results)

# Membuat folder jika belum ada (sesuaikan dengan path)
folder_path ='/content/drive/MyDrive/BerkasKuliah/Skripsi/hasil_testing/Hasilcluster18layer/HasilEvaluasiPart2'

# # Menyimpan DataFrame ke dalam file Excel
file_path = os.path.join(folder_path, 'Akurasi_Epoch70_15K.xlsx')
df_results.to_excel(file_path, index=False)

"""#Evaluasi Clustering"""

#Akurasi Khusus clustering secara keseluruhan

# Calculate metrics
silhouette = silhouette_score(encoded_features, predicted_labels_KMeans)
calinski_harabasz = calinski_harabasz_score(encoded_features, predicted_labels_KMeans)
davies_bouldin = davies_bouldin_score(encoded_features, predicted_labels_KMeans)
AR_Score = adjusted_rand_score(predicted_labels_KMeans, labels)

print("--Hasil Evaluasi Clustering untuk keseluruhan Data-- \n")
print('Silhoutte Score: ' + str(silhouette))
print('Calinski Harabasz: ' + str(calinski_harabasz))
print('davies_bouldin: ' + str(davies_bouldin))
# computes a similarity measure between two cluser (Kmeans & Agglomerative Clustering)
print('Adjusted rand score: ', str(AR_Score))


# Membuat DataFrame dari hasil evaluasi clustering
evaluation_results = {
    "Metric": ["Silhouette Score", "Calinski Harabasz", "Davies Bouldin", "Adjusted Rand Score"],
    "Value": [silhouette, calinski_harabasz, davies_bouldin, AR_Score]
}

df = pd.DataFrame(evaluation_results)

# Menyimpan DataFrame ke dalam file Excel
output_path = '/content/drive/MyDrive/BerkasKuliah/Skripsi/hasil_testing/EvaluasiClustering/hasil_EvaluasiClsutering_keseluruhan_epoch70_(15cluster).xlsx'
df.to_excel(output_path, index=False)

"""#Visualisasi Grafik"""

# Reduce dimensionality of encoded features
tsne = TSNE(n_components=2, random_state=42)
encoded_features_tsne = tsne.fit_transform(encoded_features)

# Plot the clusters
plt.scatter(encoded_features_tsne[:, 0], encoded_features_tsne[:, 1], c=predicted_labels_KMeans)
plt.title('Clusters Visualization')
plt.xlabel('Dimension 1')
plt.ylabel('Dimension 2')
plt.show()

# Reduce dimensionality of encoded features
tsne = TSNE(n_components=2, random_state=42)
encoded_features_tsne = tsne.fit_transform(encoded_features)

# Plot the clusters
plt.scatter(encoded_features_tsne[:, 0], encoded_features_tsne[:, 1], c=labels)
plt.title('Clusters Visualization')
plt.xlabel('Dimension 1')
plt.ylabel('Dimension 2')
plt.show()